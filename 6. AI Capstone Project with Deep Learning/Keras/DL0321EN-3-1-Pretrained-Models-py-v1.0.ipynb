{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://cognitiveclass.ai\"><img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/Logos/organization_logo/organization_logo.png\" width = 400> </a>\n",
    "\n",
    "<h1 align=center><font size = 5>Pre-Trained Models</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Introduction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, you will learn how to leverage pre-trained models to build image classifiers instead of building a model from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Table of Contents\n",
    "\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "\n",
    "<font size = 3> \n",
    "    \n",
    "1. <a href=\"#item31\">Import Libraries and Packages</a>\n",
    "2. <a href=\"#item32\">Download Data</a>  \n",
    "3. <a href=\"#item33\">Define Global Constants</a>  \n",
    "4. <a href=\"#item34\">Construct ImageDataGenerator Instances</a>  \n",
    "5. <a href=\"#item35\">Compile and Fit Model</a>\n",
    "\n",
    "</font>\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item31'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Import Libraries and Packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Let's start the lab by importing the libraries that we will be using in this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "First, we will import the ImageDataGenerator module since we will be leveraging it to train our model in batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall keras -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow==2.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install keras==2.2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -U plaidml-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install plaidml-keras plaidbench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\u001b[35mRunning 1024 examples with mobilenet, batch size 1, on backend plaid\u001b[0m\nINFO:plaidml:Opening device \"opencl_amd_radeon_pro_580_compute_engine.0\"\nCompiling network... Warming up... Running...\n\u001b[36m\u001b[1mExample finished, elapsed: 0.409s (compile), 9.818s (execution)\n\u001b[0m\n-----------------------------------------------------------------------------------------\nNetwork Name         Inference Latency         Time / FPS          \n-----------------------------------------------------------------------------------------\nmobilenet            9.59 ms                   4.43 ms / 225.87 fps\n\u001b[32mCorrectness: PASS, max_error: 1.675534622336272e-05, max_abs_error: 7.674098014831543e-07, fail_ratio: 0.0\u001b[0m\n"
    }
   ],
   "source": [
    "!plaidbench keras mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"KERAS_BACKEND\"] = \"plaidml.keras.backend\"\n",
    "os.environ[\"PLAIDML_EXPERIMENTAL\"] = \"1\"\n",
    "os.environ[\"PLAIDML_DEVICE_IDS\"] = \"opencl_amd_radeon_pro_580_compute_engine.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "Using plaidml.keras.backend backend.\n"
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this lab, we will be using the Keras library to build an image classifier, so let's download the Keras library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#import keras\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we will be leveraging the ResNet50 model to build our classifier, so let's download it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "from keras.applications import ResNet50\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item32'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "For your convenience, I have placed the data on a server which you can retrieve easily using the **wget** command. So let's run the following line of code to get the data. Given the large size of the image dataset, it might take some time depending on your internet speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## get the data\n",
    "#!wget https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now if you check the left directory pane, you should see the zipped file *concrete_data_week3.zip* appear. So, let's go ahead and unzip the file to access the images. Given the large number of images in the dataset, this might take a couple of minutes, so please be patient, and wait until the code finishes running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "#!unzip concrete_data_week3.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the folder *concrete_data_week3* appear in the left pane. If you open this folder by double-clicking on it, you will find that it contains two folders: *train* and *valid*. And if you explore these folders, you will find that each contains two subfolders: *positive* and *negative*. These are the same folders that we saw in the labs in the previous modules of this course, where *negative* is the negative class and it represents the concrete images with no cracks and *positive* is the positive class and it represents the concrete images with cracks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Important Note**: There are thousands and thousands of images in each folder, so please don't attempt to double click on the *negative* and *positive* folders. This may consume all of your memory and you may end up with a **50*** error. So please **DO NOT DO IT**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item33'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Define Global Constants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Here, we will define constants that we will be using throughout the rest of the lab. \n",
    "\n",
    "1. We are obviously dealing with two classes, so *num_classes* is 2. \n",
    "2. The ResNet50 model was built and trained using images of size (224 x 224). Therefore, we will have to resize our images from (227 x 227) to (224 x 224).\n",
    "3. We will training and validating the model using batches of 100 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "\n",
    "image_resize = 224\n",
    "\n",
    "batch_size_training = 100\n",
    "batch_size_validation = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item34'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Construct ImageDataGenerator Instances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In order to instantiate an ImageDataGenerator instance, we will set the **preprocessing_function** argument to *preprocess_input* which we imported from **keras.applications.resnet50** in order to preprocess our images the same way the images used to train ResNet50 model were processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will use the *flow_from_directory* method to get the training images as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 30001 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "**Your Turn**: Use the *flow_from_directory* method to get the validation images and assign the result to **validation_generator**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 10001 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "## Type your answer here\n",
    "\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Double-click __here__ for the solution.\n",
    "<!-- The correct answer is:\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week3/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "-->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a id='item35'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Build, Compile and Fit Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "In this section, we will start building our model. We will use the Sequential model class from Keras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next, we will add the ResNet50 pre-trained model to out model. However, note that we don't want to include the top layer or the output layer of the pre-trained model. We actually want to define our own output layer and train it so that it is optimized for our image dataset. In order to leave out the output layer of the pre-trained model, we will use the argument *include_top* and set it to **False**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:plaidml:Opening device \"opencl_amd_radeon_pro_580_compute_engine.0\"\n"
    }
   ],
   "source": [
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Then, we will define our output layer as a **Dense** layer, that consists of two nodes and uses the **Softmax** function as the activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the model's layers using the *layers* attribute of our model object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<keras.engine.training.Model at 0x1495c1f70>,\n <keras.layers.core.Dense at 0x143bdcc40>]"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can see that our model is composed of two sets of layers. The first set is the layers pertaining to ResNet50 and the second set is a single layer, which is our Dense layer that we defined above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can access the ResNet50 layers by running the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[<keras.engine.input_layer.InputLayer at 0x107111700>,\n <keras.layers.convolutional.ZeroPadding2D at 0x107111d00>,\n <keras.layers.convolutional.Conv2D at 0x107111e50>,\n <keras.layers.normalization.BatchNormalization at 0x122e5db80>,\n <keras.layers.core.Activation at 0x1402c17c0>,\n <keras.layers.convolutional.ZeroPadding2D at 0x1402c1d30>,\n <keras.layers.pooling.MaxPooling2D at 0x1402e6a00>,\n <keras.layers.convolutional.Conv2D at 0x1409ecd30>,\n <keras.layers.normalization.BatchNormalization at 0x1409eca30>,\n <keras.layers.core.Activation at 0x1409e6c70>,\n <keras.layers.convolutional.Conv2D at 0x1409e61f0>,\n <keras.layers.normalization.BatchNormalization at 0x1409d6e20>,\n <keras.layers.core.Activation at 0x140a20ee0>,\n <keras.layers.convolutional.Conv2D at 0x140a20580>,\n <keras.layers.convolutional.Conv2D at 0x1401c11f0>,\n <keras.layers.normalization.BatchNormalization at 0x1401c1d60>,\n <keras.layers.normalization.BatchNormalization at 0x1401c1190>,\n <keras.layers.merge.Add at 0x1401c1070>,\n <keras.layers.core.Activation at 0x140a3b4f0>,\n <keras.layers.convolutional.Conv2D at 0x140a3bd90>,\n <keras.layers.normalization.BatchNormalization at 0x140a3b730>,\n <keras.layers.core.Activation at 0x140a288b0>,\n <keras.layers.convolutional.Conv2D at 0x1430db820>,\n <keras.layers.normalization.BatchNormalization at 0x140a2f0d0>,\n <keras.layers.core.Activation at 0x1430dbca0>,\n <keras.layers.convolutional.Conv2D at 0x143113190>,\n <keras.layers.normalization.BatchNormalization at 0x143113a30>,\n <keras.layers.merge.Add at 0x1431046a0>,\n <keras.layers.core.Activation at 0x1430fc0d0>,\n <keras.layers.convolutional.Conv2D at 0x1430fce80>,\n <keras.layers.normalization.BatchNormalization at 0x143196490>,\n <keras.layers.core.Activation at 0x143191fa0>,\n <keras.layers.convolutional.Conv2D at 0x143191100>,\n <keras.layers.normalization.BatchNormalization at 0x14319fdf0>,\n <keras.layers.core.Activation at 0x1431744c0>,\n <keras.layers.convolutional.Conv2D at 0x143174fa0>,\n <keras.layers.normalization.BatchNormalization at 0x143198f40>,\n <keras.layers.merge.Add at 0x14317dc70>,\n <keras.layers.core.Activation at 0x1432a2130>,\n <keras.layers.convolutional.Conv2D at 0x1432a29d0>,\n <keras.layers.normalization.BatchNormalization at 0x1432b1760>,\n <keras.layers.core.Activation at 0x1432b83d0>,\n <keras.layers.convolutional.Conv2D at 0x1432da700>,\n <keras.layers.normalization.BatchNormalization at 0x1432dafa0>,\n <keras.layers.core.Activation at 0x1432dadf0>,\n <keras.layers.convolutional.Conv2D at 0x1432c1040>,\n <keras.layers.convolutional.Conv2D at 0x143757520>,\n <keras.layers.normalization.BatchNormalization at 0x1432c18b0>,\n <keras.layers.normalization.BatchNormalization at 0x143753b80>,\n <keras.layers.merge.Add at 0x143753e20>,\n <keras.layers.core.Activation at 0x143751bb0>,\n <keras.layers.convolutional.Conv2D at 0x143751df0>,\n <keras.layers.normalization.BatchNormalization at 0x143746ac0>,\n <keras.layers.core.Activation at 0x1437468b0>,\n <keras.layers.convolutional.Conv2D at 0x1437a1940>,\n <keras.layers.normalization.BatchNormalization at 0x1437a1d00>,\n <keras.layers.core.Activation at 0x1437b4160>,\n <keras.layers.convolutional.Conv2D at 0x1437d83d0>,\n <keras.layers.normalization.BatchNormalization at 0x1437d8c70>,\n <keras.layers.merge.Add at 0x1437cbc40>,\n <keras.layers.core.Activation at 0x1437be1c0>,\n <keras.layers.convolutional.Conv2D at 0x1437d8ac0>,\n <keras.layers.normalization.BatchNormalization at 0x1436976d0>,\n <keras.layers.core.Activation at 0x14369b070>,\n <keras.layers.convolutional.Conv2D at 0x143693e50>,\n <keras.layers.normalization.BatchNormalization at 0x143665730>,\n <keras.layers.core.Activation at 0x1436753a0>,\n <keras.layers.convolutional.Conv2D at 0x14369e8e0>,\n <keras.layers.normalization.BatchNormalization at 0x14369ec70>,\n <keras.layers.merge.Add at 0x14367c1c0>,\n <keras.layers.core.Activation at 0x143a626d0>,\n <keras.layers.convolutional.Conv2D at 0x143a62f70>,\n <keras.layers.normalization.BatchNormalization at 0x143a62910>,\n <keras.layers.core.Activation at 0x143a74850>,\n <keras.layers.convolutional.Conv2D at 0x143a6b550>,\n <keras.layers.normalization.BatchNormalization at 0x143a9bc40>,\n <keras.layers.core.Activation at 0x143a8c970>,\n <keras.layers.convolutional.Conv2D at 0x143a88280>,\n <keras.layers.normalization.BatchNormalization at 0x143a7c6d0>,\n <keras.layers.merge.Add at 0x143c5d460>,\n <keras.layers.core.Activation at 0x143c229a0>,\n <keras.layers.convolutional.Conv2D at 0x143c22d60>,\n <keras.layers.normalization.BatchNormalization at 0x143c37280>,\n <keras.layers.core.Activation at 0x143c37e80>,\n <keras.layers.convolutional.Conv2D at 0x143c3edf0>,\n <keras.layers.normalization.BatchNormalization at 0x143c536d0>,\n <keras.layers.core.Activation at 0x143c46340>,\n <keras.layers.convolutional.Conv2D at 0x144b9f940>,\n <keras.layers.convolutional.Conv2D at 0x144b8d220>,\n <keras.layers.normalization.BatchNormalization at 0x144b9fd00>,\n <keras.layers.normalization.BatchNormalization at 0x144b65850>,\n <keras.layers.merge.Add at 0x144b65a90>,\n <keras.layers.core.Activation at 0x144b88190>,\n <keras.layers.convolutional.Conv2D at 0x144b88a30>,\n <keras.layers.normalization.BatchNormalization at 0x144cdb6a0>,\n <keras.layers.core.Activation at 0x144cd6310>,\n <keras.layers.convolutional.Conv2D at 0x144ca6280>,\n <keras.layers.normalization.BatchNormalization at 0x144ca6b20>,\n <keras.layers.core.Activation at 0x144cb6af0>,\n <keras.layers.convolutional.Conv2D at 0x144cd2070>,\n <keras.layers.normalization.BatchNormalization at 0x144cb0490>,\n <keras.layers.merge.Add at 0x144cc4580>,\n <keras.layers.core.Activation at 0x144cceeb0>,\n <keras.layers.convolutional.Conv2D at 0x144cbfee0>,\n <keras.layers.normalization.BatchNormalization at 0x144cbf9d0>,\n <keras.layers.core.Activation at 0x14474f7c0>,\n <keras.layers.convolutional.Conv2D at 0x144722670>,\n <keras.layers.normalization.BatchNormalization at 0x144722f10>,\n <keras.layers.core.Activation at 0x1447361f0>,\n <keras.layers.convolutional.Conv2D at 0x144748460>,\n <keras.layers.normalization.BatchNormalization at 0x14472c850>,\n <keras.layers.merge.Add at 0x14569e970>,\n <keras.layers.core.Activation at 0x145697400>,\n <keras.layers.convolutional.Conv2D at 0x145697df0>,\n <keras.layers.normalization.BatchNormalization at 0x145697dc0>,\n <keras.layers.core.Activation at 0x145673cd0>,\n <keras.layers.convolutional.Conv2D at 0x14567a2b0>,\n <keras.layers.normalization.BatchNormalization at 0x14567ae20>,\n <keras.layers.core.Activation at 0x145685430>,\n <keras.layers.convolutional.Conv2D at 0x14567c970>,\n <keras.layers.normalization.BatchNormalization at 0x14567cd30>,\n <keras.layers.merge.Add at 0x145b919a0>,\n <keras.layers.core.Activation at 0x145b91190>,\n <keras.layers.convolutional.Conv2D at 0x145b72fd0>,\n <keras.layers.normalization.BatchNormalization at 0x145b63940>,\n <keras.layers.core.Activation at 0x145b7a280>,\n <keras.layers.convolutional.Conv2D at 0x145b890d0>,\n <keras.layers.normalization.BatchNormalization at 0x145b89970>,\n <keras.layers.core.Activation at 0x145b7b5e0>,\n <keras.layers.convolutional.Conv2D at 0x14545c1c0>,\n <keras.layers.normalization.BatchNormalization at 0x14545cdc0>,\n <keras.layers.merge.Add at 0x145436400>,\n <keras.layers.core.Activation at 0x14545b940>,\n <keras.layers.convolutional.Conv2D at 0x14542cc40>,\n <keras.layers.normalization.BatchNormalization at 0x14545cee0>,\n <keras.layers.core.Activation at 0x1454475b0>,\n <keras.layers.convolutional.Conv2D at 0x14543b610>,\n <keras.layers.normalization.BatchNormalization at 0x14543beb0>,\n <keras.layers.core.Activation at 0x1456dab20>,\n <keras.layers.convolutional.Conv2D at 0x1456a40a0>,\n <keras.layers.normalization.BatchNormalization at 0x1456a4940>,\n <keras.layers.merge.Add at 0x1456b3940>,\n <keras.layers.core.Activation at 0x1456b8eb0>,\n <keras.layers.convolutional.Conv2D at 0x1456af2b0>,\n <keras.layers.normalization.BatchNormalization at 0x1456af280>,\n <keras.layers.core.Activation at 0x1457e0fa0>,\n <keras.layers.convolutional.Conv2D at 0x1456c9b80>,\n <keras.layers.normalization.BatchNormalization at 0x1457a5850>,\n <keras.layers.core.Activation at 0x1457b64c0>,\n <keras.layers.convolutional.Conv2D at 0x1457ddac0>,\n <keras.layers.convolutional.Conv2D at 0x1457ddd30>,\n <keras.layers.normalization.BatchNormalization at 0x1457ca370>,\n <keras.layers.normalization.BatchNormalization at 0x1457dde80>,\n <keras.layers.merge.Add at 0x1457bdc70>,\n <keras.layers.core.Activation at 0x1480e4310>,\n <keras.layers.convolutional.Conv2D at 0x1480e4bb0>,\n <keras.layers.normalization.BatchNormalization at 0x1480f4820>,\n <keras.layers.core.Activation at 0x1480f7490>,\n <keras.layers.convolutional.Conv2D at 0x14810d400>,\n <keras.layers.normalization.BatchNormalization at 0x1480ffc70>,\n <keras.layers.core.Activation at 0x148104430>,\n <keras.layers.convolutional.Conv2D at 0x1481042e0>,\n <keras.layers.normalization.BatchNormalization at 0x148cef0a0>,\n <keras.layers.merge.Add at 0x148ce9eb0>,\n <keras.layers.core.Activation at 0x148d1c8e0>,\n <keras.layers.convolutional.Conv2D at 0x148d1cc70>,\n <keras.layers.normalization.BatchNormalization at 0x148d08100>,\n <keras.layers.core.Activation at 0x148d08a60>,\n <keras.layers.convolutional.Conv2D at 0x148cf9910>,\n <keras.layers.normalization.BatchNormalization at 0x148cf9cd0>,\n <keras.layers.core.Activation at 0x1495d51f0>,\n <keras.layers.convolutional.Conv2D at 0x1495a2700>,\n <keras.layers.normalization.BatchNormalization at 0x1495e0970>,\n <keras.layers.merge.Add at 0x1495b2c10>,\n <keras.layers.core.Activation at 0x1495b8df0>,\n <keras.layers.pooling.GlobalAveragePooling2D at 0x1495d06d0>]"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model.layers[0].layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since the ResNet50 model has already been trained, then we want to tell our model not to bother with training the ResNet part, but to train only our dense output layer. To do that, we run the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.layers[0].trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "And now using the *summary* attribute of the model, we can see how many parameters we will need to optimize in order to train the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 2048)              23587712  \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 4098      \n=================================================================\nTotal params: 23,591,810\nTrainable params: 4,098\nNon-trainable params: 23,587,712\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Next we compile our model using the **adam** optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Before we are able to start the training process, with an ImageDataGenerator, we will need to define how many steps compose an epoch. Typically, that is the number of images divided by the batch size. Therefore, we define our steps per epoch as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "301"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "steps_per_epoch_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "101"
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "steps_per_epoch_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Finally, we are ready to start training our model. Unlike a conventional deep learning training were data is not streamed from a directory, with an ImageDataGenerator where data is augmented in batches, we use the **fit_generator** method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/2\n301/301 [==============================] - 1375s 5s/step - loss: 0.0505 - acc: 0.9842 - val_loss: 1.1986 - val_acc: 0.7072\nEpoch 2/2\n301/301 [==============================] - 1451s 5s/step - loss: 0.0185 - acc: 0.9937 - val_loss: 384112311329025495930826129408.0000 - val_acc: 0.8436\n"
    }
   ],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "model.save('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now that the model is trained, you are ready to start using it to classify images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Since training can take a long time when building deep learning models, it is always a good idea to save your model once the training is complete if you believe you will be using the model again later. You will be using this model in the next module, so go ahead and save your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "collapsed": true,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#model.save('classifier_resnet_model.h5')\n",
    "\n",
    "# load model\n",
    "from keras.models import load_model\n",
    "\n",
    "model_resnet = load_model('classifier_resnet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Found 500 images belonging to 2 classes.\n"
    }
   ],
   "source": [
    "test_datagen_resnet = ImageDataGenerator()\n",
    "validation_generator_resnet = test_datagen_resnet.flow_from_directory(\n",
    "    'concrete_data_week4/test',\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_resnet = model_resnet.evaluate_generator(\n",
    "    validation_generator_resnet, \n",
    "    workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[1.503771993637085, 0.5500000002384186]"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "score_resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, you should see the model file *classifier_resnet_model.h5* apprear in the left directory pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Thank you for completing this lab!\n",
    "\n",
    "This notebook was created by Alex Aklson. I hope you found this lab interesting and educational."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This notebook is part of a course on **Coursera** called *AI Capstone Project with Deep Learning*. If you accessed this notebook outside the course, you can take this course online by clicking [here](https://cocl.us/DL0321EN_Coursera_Week3_LAB1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "deletable": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<hr>\n",
    "\n",
    "Copyright &copy; 2020 [IBM Developer Skills Network](https://cognitiveclass.ai/?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu). This notebook and its source code are released under the terms of the [MIT License](https://bigdatauniversity.com/mit-license/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('plaidml-venv': venv)",
   "language": "python",
   "name": "python_defaultSpec_1596954677875"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}