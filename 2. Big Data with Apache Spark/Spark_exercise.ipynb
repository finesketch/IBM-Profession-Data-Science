{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:1: error: illegal start of definition\n",
       "# setup Apache Apark\n",
       "^\n",
       "<console>:2: error: ';' expected but '.' found.\n",
       "from IPython.display import Markdown, display\n",
       "            ^\n",
       "<console>:3: error: ':' expected but ')' found.\n",
       "def printmd(string):\n",
       "                  ^\n",
       "<console>:4: error: unclosed character literal\n",
       "    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n",
       "                                                                 ^\n",
       "<console>:7: error: unclosed character literal\n",
       "if ('sc' in locals() or 'sc' in globals()):\n",
       "       ^\n",
       "<console>:7: error: unclosed character literal\n",
       "if ('sc' in locals() or 'sc' in globals()):\n",
       "                           ^\n",
       "<console>:8: error: unclosed character literal\n",
       "    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')\n",
       "                                                                                                                                                                                           ^\n",
       "<console>:12: error: unclosed character literal\n",
       "print('installation of pyspark completed.')\n",
       "                                         ^\n",
       "<console>:18: error: unclosed character literal\n",
       "    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')\n",
       "                                                                                           ^\n",
       "<console>:20: error: unclosed character literal\n",
       "print('pyspark is ready!')\n",
       "                        ^\n",
       "<console>:28: error: unclosed character literal\n",
       "print('SparkContext session is active.')\n",
       "                                      ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup Apache Apark\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n",
    "\n",
    "\n",
    "if ('sc' in locals() or 'sc' in globals()):\n",
    "    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')\n",
    "\n",
    "!pip install pyspark==2.4.5\n",
    "\n",
    "print('installation of pyspark completed.')\n",
    "\n",
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError as e:\n",
    "    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')\n",
    "    \n",
    "print('pyspark is ready!')\n",
    "\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print('SparkContext session is active.')\n",
    "\n",
    "rdd = sc.parallelize(range(100))\n",
    "\n",
    "print(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var rdd = sc.parallelize(List.range(0,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ParallelCollectionRDD[0] at parallelize at <console>:27"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name: Compile Error\n",
       "Message: <console>:1: error: illegal start of simple expression\n",
       "var rdd1 = sc.parallelize([100] + range(100) + [102, 103, 104, 104, 1000, 100])\n",
       "                          ^\n",
       "\n",
       "StackTrace: "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var rdd1 = sc.parallelize([100] + range(100) + [102, 103, 104, 104, 1000, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum = rdd1.sum()\n",
    "n = rdd1.count()\n",
    "mean = sum / n\n",
    "print mean"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
