{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standard deviation tells you how wide the data is spread around the mean. So if the standard deviation is low, then all the values are very close to the mean value, which can be seen here. This diagram is called a histogram, and tells us how many values of a list of values are within a certain range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is actually a very good idea to user *median* and *standard deviation* to calculate the *mean*. Median is telling you an outlier resistant average of distances and standard deviation tells you about the range where values are spread around. In addition you could calculate a threshold for cases where the door was open as well and see whether the thresholds plus one or two standard deviation overlap or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark==2.4.5 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (2.4.5)\n",
      "Requirement already satisfied: py4j==0.10.7 in /home/jupyterlab/conda/envs/python/lib/python3.6/site-packages (from pyspark==2.4.5) (0.10.7)\n",
      "installation of pyspark completed.\n",
      "pyspark is ready!\n",
      "SparkContext session is active.\n",
      "PythonRDD[1] at RDD at PythonRDD.scala:53\n"
     ]
    }
   ],
   "source": [
    "# setup Apache Apark\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown('# <span style=\"color:red\">'+string+'</span>'))\n",
    "\n",
    "\n",
    "if ('sc' in locals() or 'sc' in globals()):\n",
    "    printmd('<<<<<!!!!! It seems that you are running in a IBM Watson Studio Apache Spark Notebook. Please run it in an IBM Watson Studio Default Runtime (without Apache Spark) !!!!!>>>>>')\n",
    "\n",
    "!pip install pyspark==2.4.5\n",
    "\n",
    "print('installation of pyspark completed.')\n",
    "\n",
    "try:\n",
    "    from pyspark import SparkContext, SparkConf\n",
    "    from pyspark.sql import SparkSession\n",
    "except ImportError as e:\n",
    "    printmd('<<<<<!!!!! Please restart your kernel after installing Apache Spark !!!!!>>>>>')\n",
    "    \n",
    "print('pyspark is ready!')\n",
    "\n",
    "sc = SparkContext.getOrCreate(SparkConf().setMaster(\"local[*]\"))\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print('SparkContext session is active.')\n",
    "\n",
    "rdd = sc.parallelize(range(100))\n",
    "\n",
    "print(rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.5\n"
     ]
    }
   ],
   "source": [
    "sum = rdd.sum()\n",
    "n = rdd.count()\n",
    "mean = sum / n\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.86607004772212"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "\n",
    "sqrt(rdd.map(lambda x : pow(x - mean, 2)).sum() / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd1 = sc.parallelize([49] * 100)\n",
    "\n",
    "sum = rdd1.sum()\n",
    "n = rdd1.count()\n",
    "mean = sum / n\n",
    "print(mean)\n",
    "\n",
    "sqrt(rdd1.map(lambda x : pow(x - mean, 2)).sum() / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49.504950495049506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5.0495049504950495"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd2 = sc.parallelize([49] * 100 + [100])\n",
    "\n",
    "sum = rdd2.sum()\n",
    "n = rdd2.count()\n",
    "mean = sum / n\n",
    "print(mean)\n",
    "\n",
    "sqrt(rdd2.map(lambda x : pow(x - mean, 2)).sum() / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'range' and 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-a7541f19eb19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrdd3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrdd3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'range' and 'list'"
     ]
    }
   ],
   "source": [
    "rdd3 = sc.parallelize(range(100) + [10000])\n",
    "\n",
    "sum = rdd3.sum()\n",
    "n = rdd3.count()\n",
    "mean = sum / n\n",
    "print(mean)\n",
    "\n",
    "sqrt(rdd2.map(lambda x : pow(x - mean, 2)).sum() / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
